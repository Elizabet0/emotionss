{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d466522-5b6d-448a-a737-778b96a09ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dbec3a-e92e-43d4-8b08-f9306ae5d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for i, em in enumerate(self.classes):\n",
    "            em_dir = os.path.join(root_dir, em)\n",
    "            for img in os.listdir(em_dir):\n",
    "                img_path = os.path.join(em_dir, img)\n",
    "                image = Image.open(img_path)\n",
    "                img_array = np.array(image)\n",
    "                img_tensor = torch.from_numpy(img_array) / 255.0\n",
    "                img_tensor = img_tensor.unsqueeze(0)\n",
    "                self.images.append(img_tensor)\n",
    "                self.labels.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6698390-1835-4725-a26a-95dcb14b440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(),  \n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),  \n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Flatten(), \n",
    "            nn.Dropout(0.5), \n",
    "            nn.Linear(64 * 6 * 6, 256), nn.BatchNorm1d(256), nn.ReLU(), \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 7), \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e7743bf-9a56-4884-9ef7-d834c9fa2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"../data/train\")\n",
    "test_dataset = load_dataset(\"../data/test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245a087d-522e-46b7-abb5-a5e34752cf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, acc: 48.97%\n",
      "epoch 2, acc: 53.79%\n",
      "epoch 3, acc: 50.29%\n",
      "epoch 4, acc: 55.98%\n",
      "epoch 5, acc: 52.70%\n",
      "epoch 6, acc: 59.38%\n",
      "epoch 7, acc: 59.14%\n",
      "epoch 8, acc: 59.61%\n",
      "epoch 9, acc: 59.61%\n",
      "epoch 10, acc: 60.23%\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "batch_size=64\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(10):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            output = model(images)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    scheduler.step()\n",
    "    res = 100*correct/total\n",
    "    print(f\"epoch {i +1}, acc: {res:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b826aa7a-9e81-49a3-a5ec-0507fa3f90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc=60.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "949b656c-57f4-4b22-96c5-14614f73fc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, acc: 58.01%\n",
      "epoch 12, acc: 59.17%\n",
      "epoch 13, acc: 58.87%\n",
      "epoch 14, acc: 60.62%\n",
      "epoch 15, acc: 60.21%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "for epoch in range(10, 15):\n",
    "    model.train()\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            output = model(images)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    scheduler.step()\n",
    "    res = 100 * correct / total\n",
    "    print(f\"epoch {epoch+1}, acc: {res:.2f}%\")\n",
    "\n",
    "    if res > best_acc:\n",
    "        best_acc = res\n",
    "        torch.save(model.state_dict(), f\"../best_models/model_checkpoint_{res:.2f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ec01e-4de7-40db-807f-5be455bdf714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
